Index: notebooks/04_TRANSFORM_DATA_INTO_TIME_SERIES.ipynb
===================================================================
diff --git a/notebooks/04_TRANSFORM_DATA_INTO_TIME_SERIES.ipynb b/notebooks/04_TRANSFORM_DATA_INTO_TIME_SERIES.ipynb
deleted file mode 100644
--- a/notebooks/04_TRANSFORM_DATA_INTO_TIME_SERIES.ipynb	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ /dev/null	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
@@ -1,164 +0,0 @@
-{
- "cells": [
-  {
-   "cell_type": "code",
-   "execution_count": 1,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "import pandas as pd\n",
-    "from src.core.paths import CLEANED_DATA\n",
-    "\n",
-    "trips = pd.read_parquet(path = CLEANED_DATA/\"final.parquet\")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 2,
-   "metadata": {},
-   "outputs": [
-    {
-     "data": {
-      "text/html": [
-       "<div>\n",
-       "<style scoped>\n",
-       "    .dataframe tbody tr th:only-of-type {\n",
-       "        vertical-align: middle;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe tbody tr th {\n",
-       "        vertical-align: top;\n",
-       "    }\n",
-       "\n",
-       "    .dataframe thead th {\n",
-       "        text-align: right;\n",
-       "    }\n",
-       "</style>\n",
-       "<table border=\"1\" class=\"dataframe\">\n",
-       "  <thead>\n",
-       "    <tr style=\"text-align: right;\">\n",
-       "      <th></th>\n",
-       "      <th>start_time</th>\n",
-       "      <th>stop_time</th>\n",
-       "      <th>start_latitude</th>\n",
-       "      <th>start_longitude</th>\n",
-       "      <th>stop_latitude</th>\n",
-       "      <th>stop_longitude</th>\n",
-       "    </tr>\n",
-       "  </thead>\n",
-       "  <tbody>\n",
-       "    <tr>\n",
-       "      <th>0</th>\n",
-       "      <td>2014-06-30 23:57:00</td>\n",
-       "      <td>2014-07-01 00:07:00</td>\n",
-       "      <td>41.939304</td>\n",
-       "      <td>-87.668278</td>\n",
-       "      <td>41.945514</td>\n",
-       "      <td>-87.646477</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>1</th>\n",
-       "      <td>2014-06-30 23:56:00</td>\n",
-       "      <td>2014-07-01 00:00:00</td>\n",
-       "      <td>41.864819</td>\n",
-       "      <td>-87.647128</td>\n",
-       "      <td>41.869388</td>\n",
-       "      <td>-87.655475</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>2</th>\n",
-       "      <td>2014-06-30 23:33:00</td>\n",
-       "      <td>2014-06-30 23:35:00</td>\n",
-       "      <td>41.921687</td>\n",
-       "      <td>-87.653714</td>\n",
-       "      <td>41.919936</td>\n",
-       "      <td>-87.648830</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>3</th>\n",
-       "      <td>2014-06-30 23:26:00</td>\n",
-       "      <td>2014-07-01 00:24:00</td>\n",
-       "      <td>41.877702</td>\n",
-       "      <td>-87.649654</td>\n",
-       "      <td>49.318630</td>\n",
-       "      <td>11.131904</td>\n",
-       "    </tr>\n",
-       "    <tr>\n",
-       "      <th>4</th>\n",
-       "      <td>2014-06-30 23:16:00</td>\n",
-       "      <td>2014-06-30 23:26:00</td>\n",
-       "      <td>41.872165</td>\n",
-       "      <td>-87.661434</td>\n",
-       "      <td>41.877702</td>\n",
-       "      <td>-87.649654</td>\n",
-       "    </tr>\n",
-       "  </tbody>\n",
-       "</table>\n",
-       "</div>"
-      ],
-      "text/plain": [
-       "           start_time           stop_time  start_latitude  start_longitude  \\\n",
-       "0 2014-06-30 23:57:00 2014-07-01 00:07:00       41.939304       -87.668278   \n",
-       "1 2014-06-30 23:56:00 2014-07-01 00:00:00       41.864819       -87.647128   \n",
-       "2 2014-06-30 23:33:00 2014-06-30 23:35:00       41.921687       -87.653714   \n",
-       "3 2014-06-30 23:26:00 2014-07-01 00:24:00       41.877702       -87.649654   \n",
-       "4 2014-06-30 23:16:00 2014-06-30 23:26:00       41.872165       -87.661434   \n",
-       "\n",
-       "   stop_latitude  stop_longitude  \n",
-       "0      41.945514      -87.646477  \n",
-       "1      41.869388      -87.655475  \n",
-       "2      41.919936      -87.648830  \n",
-       "3      49.318630       11.131904  \n",
-       "4      41.877702      -87.649654  "
-      ]
-     },
-     "execution_count": 2,
-     "metadata": {},
-     "output_type": "execute_result"
-    }
-   ],
-   "source": [
-    "trips.head()"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 3,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "trips[\"start_hour\"] = trips[\"start_time\"].dt.floor(\"H\")\n",
-    "trips[\"stop_hour\"] = trips[\"stop_time\"].dt.floor(\"H\")"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": []
-  }
- ],
- "metadata": {
-  "kernelspec": {
-   "display_name": ".venv",
-   "language": "python",
-   "name": "python3"
-  },
-  "language_info": {
-   "codemirror_mode": {
-    "name": "ipython",
-    "version": 3
-   },
-   "file_extension": ".py",
-   "mimetype": "text/x-python",
-   "name": "python",
-   "nbconvert_exporter": "python",
-   "pygments_lexer": "ipython3",
-   "version": "3.11.4"
-  },
-  "orig_nbformat": 4
- },
- "nbformat": 4,
- "nbformat_minor": 2
-}
Index: .idea/inspectionProfiles/Project_Default.xml
===================================================================
diff --git a/.idea/inspectionProfiles/Project_Default.xml b/.idea/inspectionProfiles/Project_Default.xml
deleted file mode 100644
--- a/.idea/inspectionProfiles/Project_Default.xml	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ /dev/null	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
@@ -1,15 +0,0 @@
-<component name="InspectionProjectProfileManager">
-  <profile version="1.0">
-    <option name="myName" value="Project Default" />
-    <inspection_tool class="PyPep8NamingInspection" enabled="true" level="WEAK WARNING" enabled_by_default="true">
-      <option name="ignoredErrors">
-        <list>
-          <option value="N806" />
-        </list>
-      </option>
-    </inspection_tool>
-    <inspection_tool class="PyTypeCheckerInspection" enabled="false" level="WARNING" enabled_by_default="false" />
-    <inspection_tool class="PyUnboundLocalVariableInspection" enabled="false" level="WARNING" enabled_by_default="false" />
-    <inspection_tool class="PyUnreachableCodeInspection" enabled="false" level="WARNING" enabled_by_default="false" />
-  </profile>
-</component>
\ No newline at end of file
Index: src/core/data_extraction.py
===================================================================
diff --git a/src/core/data_extraction.py b/src/core/data_extraction.py
deleted file mode 100644
--- a/src/core/data_extraction.py	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ /dev/null	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
@@ -1,473 +0,0 @@
-import sys
-import requests
-import pandas as pd
-from pathlib import Path
-from zipfile import ZipFile
-from typing import Optional, List
-from tqdm import tqdm
-from src.core.paths import RAW_DATA_DIR
-
-sys.path.insert(0, "/home/kobina/cyclistic-bike-sharing-data/src")
-
-
-def download_one_file_of_raw_data(
-        year: int,
-        month: Optional[int] = None,
-        quarters: Optional[List[int]] = None,
-        file_name: Optional[str] = None
-) -> Path:
-    if year == 2014:
-
-        URL_1 = f"https://divvy-tripdata.s3.amazonaws.com/Divvy_Stations_Trips_{year}_Q{quarters[0]}Q{quarters[1]}.zip"
-        URL_2 = f"https://divvy-tripdata.s3.amazonaws.com/Divvy_Stations_Trips_{year}_Q{quarters[2]}Q{quarters[3]}.zip"
-
-        response_1 = requests.get(URL_1)
-        response_2 = requests.get(URL_2)
-
-        if response_1.status_code == 200:
-
-            path = RAW_DATA_DIR / f"Divvy_Trips_{year}_Q1Q2.zip"
-            open(path, "wb").write(response_1.content)
-
-            with ZipFile(file=path, mode="r") as zip:
-                zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}_Q1Q2")
-
-        else:
-            raise Exception(f"{URL_1} is not available")
-
-        if response_2.status_code == 200:
-
-            path = RAW_DATA_DIR / f"Divvy_Stations_Trips_{year}_Q3Q4.zip"
-            open(path, "wb").write(response_2.content)
-
-            with ZipFile(file=path, mode="r") as zip:
-                zip.extractall(RAW_DATA_DIR)
-
-        else:
-            raise Exception(f"{URL_2} is not available")
-
-    if year == 2015:
-
-        if file_name == f"Divvy_Trips_{year}-Q1Q2":
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{file_name}.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"Divvy_Trips_{year}-Q1Q2.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}-Q1Q2")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-        elif file_name == f"Divvy_Trips_{year}_Q3Q4":
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{file_name}.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"Divvy_Trips_{year}_Q3Q4.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}_Q3Q4")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-    if year == 2016:
-
-        if file_name == f"Divvy_Trips_{year}_Q1Q2":
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{file_name}.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"{file_name}zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / file_name)
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-        elif file_name == f"Divvy_Trips_{year}_Q3Q4":
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{file_name}.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"{file_name}.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR)
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-    if year == 2017:
-
-        if file_name == f"Divvy_Trips_{year}_Q1Q2":
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{file_name}.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"Divvy_Trips_{year}_Q1Q2.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}_Q1Q2")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-        elif file_name == f"Divvy_Trips_{year}_Q3Q4":
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{file_name}.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"Divvy_Trips_{year}_Q3Q4.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}_Q3Q4")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-    if year in [2018, 2019]:
-
-        for quarter in quarters:
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_{year}_Q{quarter}.zip"
-
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-                path = RAW_DATA_DIR / f"Divvy_Trips_{year}_Q{quarter}.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}_Q{quarter}")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-    if year == 2020:
-
-        if quarters == [1]:
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/Divvy_Trips_{year}_Q1.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"Divvy_Trips_{year}_Q1.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"Divvy_Trips_{year}_Q1")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-        if month >= 4:
-
-            URL = f"https://divvy-tripdata.s3.amazonaws.com/{year}{month:02d}-divvy-tripdata.zip"
-            response = requests.get(URL)
-
-            if response.status_code == 200:
-
-                path = RAW_DATA_DIR / f"{year}{month}-divvy-tripdata.zip"
-                open(path, "wb").write(response.content)
-
-                with ZipFile(file=path, mode="r") as zip:
-                    zip.extractall(RAW_DATA_DIR / f"{year}{month:02d}-divvy-tripdata")
-
-            else:
-                raise Exception(f"{URL} is not available")
-
-    if year >= 2021:
-
-        URL = f"https://divvy-tripdata.s3.amazonaws.com/{year}{month:02d}-divvy-tripdata.zip"
-
-        response = requests.get(URL)
-
-        if response.status_code == 200:
-            path = RAW_DATA_DIR / f"{year}{month:02d}-divvy-tripdata.zip"
-            open(path, "wb").write(response.content)
-
-            with ZipFile(file=path, mode="r") as zip:
-                zip.extractall(RAW_DATA_DIR / f"{year}{month:02d}-divvy-tripdata")
-
-        else:
-            raise Exception(f"{URL} is not available")
-
-
-def check_for_file_and_download(
-        year: int,
-        file_name: str,
-        quarters: Optional[List[int]] = None,
-        month: Optional[List[int]] = None
-):
-    if quarters is not None:
-
-        local_file = RAW_DATA_DIR / file_name
-
-        if not local_file.exists():
-
-            try:
-                print(f"Downloading and extracting {file_name}.zip")
-
-                # Download the file
-                download_one_file_of_raw_data(year=year, file_name=file_name, quarters=quarters)
-
-            except:
-                print(f"{file_name} is not available")
-
-        else:
-            print(f"{file_name} is already in local storage")
-
-    elif month is not None:
-
-        local_file = RAW_DATA_DIR / f"{year}{month:02d}-divvy-tripdata"
-
-        if not local_file.exists():
-
-            try:
-                print(f"Downloading and extracting {year}{month:02d}-divvy-tripdata.zip")
-
-                # Download the file
-                download_one_file_of_raw_data(year=year, month=month)
-
-            except:
-                print(f"{year}{month:02d}-divvy-tripdata is not available")
-
-        else:
-            print(f"The file {year}{month:02d}-divvy-tripdata.zip is already in local storage")
-
-
-def get_dataframe_from_folder(year: int, file_name: str):
-    data = pd.DataFrame()
-
-    if year == 2014:
-
-        if file_name == f"Divvy_Trips_{year}_Q1Q2":
-
-            data_q1_q2 = pd.read_csv(RAW_DATA_DIR / f"{file_name}/{file_name}.csv")
-            data = pd.concat([data, data_q1_q2])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-        else:
-            other_months = pd.read_csv(RAW_DATA_DIR / f"Divvy_Stations_Trips_2014_Q3Q4/{file_name}.csv")
-            data = pd.concat([data, other_months])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-    elif year == 2015:
-
-        if file_name == f"Divvy_Trips_{year}-Q1Q2":
-
-            for quarter in [1, 2]:
-                quarter_data = pd.read_csv(RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}-Q{quarter}.csv")
-                data = pd.concat([data, quarter_data])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-        elif file_name == f"Divvy_Trips_{year}_Q3Q4":
-
-            for month in [7, 8, 9]:
-                intermediate_month = pd.read_csv(
-                    RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_{month:02d}.csv"
-                )
-
-                data = pd.concat([data, intermediate_month])
-
-            last_quarter = pd.read_csv(
-                RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_Q4.csv"
-            )
-
-            data = pd.concat([data, last_quarter])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-    elif year == 2016:
-
-        if file_name == f"Divvy_Trips_{year}_Q1Q2":
-
-            first_quarter = pd.read_csv(RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_Q1.csv")
-
-            for month in [4, 5, 6]:
-                second_quarter_month = pd.read_csv(RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_{month:02d}.csv")
-                data = pd.concat([data, first_quarter, second_quarter_month])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-        elif file_name == f"Divvy_Trips_{year}_Q3Q4":
-
-            for quarter in [3, 4]:
-                quarter_data = pd.read_csv(RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_Q{quarter}.csv")
-                data = pd.concat([data, quarter_data])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-    elif year == 2017:
-
-        if file_name == f"Divvy_Trips_{year}_Q1Q2":
-
-            for quarter in [1, 2]:
-                quarter_data = pd.read_csv(RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_Q{quarter}.csv")
-                data = pd.concat([data, quarter_data])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-        if file_name == f"Divvy_Trips_{year}_Q3Q4":
-
-            for quarter in [3, 4]:
-                quarter_data = pd.read_csv(RAW_DATA_DIR / f"{file_name}/Divvy_Trips_{year}_Q{quarter}.csv")
-                data = pd.concat([data, quarter_data])
-
-            if data.empty:
-                return pd.DataFrame()
-
-            else:
-                return data
-
-    else:
-
-        data_one_month = pd.read_csv(RAW_DATA_DIR / f"{file_name}/{file_name}.csv")
-        data = pd.concat([data, data_one_month])
-
-        if data.empty:
-            return pd.DataFrame()
-
-        else:
-            return data
-
-
-def load_raw_data(
-        year: int,
-        months: Optional[List[int]] = None,
-        quarters: Optional[List[int]] = None
-) -> pd.DataFrame:
-    if year == 2014:
-
-        file_names_2014 = [
-            f"Divvy_Trips_{year}_Q1Q2", f"Divvy_Trips_{year}-Q3-07", f"Divvy_Trips_{year}-Q3-0809",
-            f"Divvy_Trips_{year}-Q4"
-        ]
-
-        for file_name in file_names_2014:
-            # Download the relevant files and return the corresponding dataframes
-            check_for_file_and_download(year=year, file_name=file_name, quarters=quarters)
-            yield get_dataframe_from_folder(year=year, file_name=file_name)
-
-    if year == 2015:
-
-        file_names_2015 = [
-            f"Divvy_Trips_{year}-Q1Q2", f"Divvy_Trips_{year}_Q3Q4"
-        ]
-
-        for file_name in file_names_2015:
-            check_for_file_and_download(year=year, file_name=file_name, quarters=[1])
-            yield get_dataframe_from_folder(year=year, file_name=file_name)
-
-    if year == 2016:
-
-        # Download the relevant files
-        check_for_file_and_download(year=year, file_name=f"Divvy_Trips_{year}_Q1Q2", quarters=[1, 2])
-        check_for_file_and_download(year=year, file_name=f"Divvy_Trips_{year}_Q3Q4", quarters=[3, 4])
-
-        file_names_2016 = [
-            f"Divvy_Trips_{year}_Q1Q2", f"Divvy_Trips_{year}_Q3Q4"
-        ]
-
-        for file_name in tqdm(file_names_2016):
-            yield get_dataframe_from_folder(year=year, file_name=file_name)
-
-    if year == 2017:
-
-        # Download the relevant files
-        check_for_file_and_download(year=year, file_name=f"Divvy_Trips_{year}_Q1Q2", quarters=[1, 2])
-        check_for_file_and_download(year=year, file_name=f"Divvy_Trips_{year}_Q3Q4", quarters=[3, 4])
-
-        file_names_2017 = [
-            f"Divvy_Trips_{year}_Q1Q2", f"Divvy_Trips_{year}_Q3Q4"
-        ]
-
-        for file_name in file_names_2017:
-            yield get_dataframe_from_folder(year=year, file_name=file_name)
-
-    if year in [2018, 2019]:
-
-        for quarter in quarters:
-            check_for_file_and_download(year=year, file_name=f"Divvy_Trips_{year}_Q{quarter}", quarters=[quarter])
-            yield get_dataframe_from_folder(year=year, file_name=f"Divvy_Trips_{year}_Q{quarter}")
-
-    if year == 2020 and quarters == [1]:
-        check_for_file_and_download(year=2020, quarters=[1], file_name=f"Divvy_Trips_{year}_Q1")
-        yield get_dataframe_from_folder(year=2020, file_name=f"Divvy_Trips_{year}_Q1")
-
-    if year == 2020 and quarters is None:
-
-        months = list(range(4, 13))
-
-        for month in tqdm(months):
-            check_for_file_and_download(year=year, month=month, file_name=f"{year}{month:02d}-divvy-tripdata")
-            yield get_dataframe_from_folder(year=year, file_name=f"{year}{month:02d}-divvy-tripdata")
-
-    if year >= 2021:
-
-        # Download the specified year's worth of data if no month is specified
-        if months is None:
-            months = list(range(1, 13))
-
-        # Download data for only the month specified by the integer "month"
-        elif isinstance(months, list):
-            months = months
-
-        for month in tqdm(months):
-            check_for_file_and_download(year=year, month=month, file_name=f"{year}{month:02d}-divvy-tripdata")
-            yield get_dataframe_from_folder(year=year, file_name=f"{year}{month:02d}-divvy-tripdata")
Index: src/core/miscellaneous.py
===================================================================
diff --git a/src/core/miscellaneous.py b/src/core/miscellaneous.py
deleted file mode 100644
--- a/src/core/miscellaneous.py	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ /dev/null	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
@@ -1,199 +0,0 @@
-import sys
-import pandas as pd
-from tqdm import tqdm
-from geopy.geocoders import Nominatim, Photon
-
-sys.path.insert(0, "/home/kobina/cyclistic-bike-sharing-data/src")
-
-
-# SAVING DATA
-def concat_to_parquet(
-        list_of_dataframes: list,
-        parquet_name: str,
-        folder_name: str
-):
-    """
-    This function takes the elements of a list of dataframes, 
-    concatenates them, and returns the result as a .parquet file.
-    """
-
-    return pd.concat(list_of_dataframes).to_parquet(
-        path=f"{folder_name}/{parquet_name}.parquet"
-    )
-
-
-def save_as_parquet(
-        list_of_dataframes: list,
-        folder_name: str):
-    """
-    This function takes a list of dataframes and saves each as
-    a .pkl file, placing it in a specified folder. Each .pkl 
-    file is named according to its position in the list of
-    dataframes that it came from.
-    """
-
-    for i in tqdm(enumerate(list_of_dataframes)):
-        i[1].to_parquet(path=f"{folder_name}/{i[0]}.parquet")
-
-
-# MEMORY MANAGEMENT
-
-def view_memory_usage(
-        data: pd.DataFrame,
-        column: str):
-    """
-    This function allows us to view the amount of memory being 
-    used by one or more columns of a given dataframe.
-    """
-
-    yield data[column].memory_usage(index=False, deep=True)
-
-
-def change_column_data_type(
-        data: pd.DataFrame,
-        columns: list,
-        to_format: str):
-    """
-    This function changes the datatype of one or more columns of 
-    a given dataframe.
-    """
-
-    data[columns] = data[columns].astype(to_format)
-
-
-# DATA CLEANING
-
-def find_first_nan(
-        data: pd.DataFrame,
-        missing: bool,
-        just_reveal: bool
-):
-    """
-    When "missing" is set to True, this function will look
-    through the first column of the dataframe, and tell us
-    on which row a missing value first occurs.
-
-    When "missing" is set to False, the function tells 
-    us on which row a non-missing value first occurs.
-    """
-
-    for i in tqdm(range(len(data))):
-
-        if pd.isnull(data.iloc[i, 0]) == missing:
-
-            if just_reveal is True:
-
-                print(i)
-                break
-
-            else:
-                return i
-                break
-
-
-# GEOCODING
-
-def use_primary_geocoder(places: list,):
-    """
-    This function initialises the Nominatim geocoder, and takes a list 
-    of place names. It then generates a precise location using the geocoder, 
-    and creates key, value pairs of each place name with its respective 
-    location. 
-
-    Some of the places will not be successfully processed by the geocoder, 
-    causing it (the geocoder) to return "None". For each of these, I 
-    would like the function to provide the string below as the value
-    corresponding to the place name (the key). The reason why a 
-    string was used instead of the default "None" is that "None" as 
-    a data type is non-iterable.
-    """
-
-    places_and_points = {}
-    geolocator = Nominatim(user_agent="maadabrandon@protonmail.com")
-
-    for place in tqdm(places):
-
-        if geolocator.geocode(place, timeout=120) is None:
-
-            places_and_points[f"{place}"] = (0,0)
-
-        else:
-
-            places_and_points[f"{place}"] = geolocator.geocode(place, timeout=None)[-1]
-
-    return places_and_points
-
-
-def use_secondary_geocoder(
-        data: pd.DataFrame,
-        column_of_station_names: str,
-        row_indices: list,
-
-):
-
-    non_geocoded_places = list(
-        data.iloc[
-            row_indices, data.columns.get_loc(column_of_station_names)
-        ].unique()
-    )
-
-    remaining_places_with_points = {}
-    geolocator = Photon()
-
-    for place in tqdm(non_geocoded_places):
-
-        if geolocator.geocode(place) is None:
-            remaining_places_with_points[f"{place}"] = (0, 0)
-
-        else:
-            remaining_places_with_points[f"{place}"] = geolocator.geocode(place, timeout=1000)[-1]
-
-    return remaining_places_with_points
-
-
-def add_coordinates_to_dataframe(
-        data: pd.DataFrame,
-        places_and_points: dict,
-        start_or_stop: str
-):
-
-    """
-    After forming the dictionary of places and coordinates, this function isolates
-    the latitudes, and longitudes and place them in named appropriately named
-    columns of a target dataframe.
-    """
-
-    if start_or_stop == "start":
-        points = [
-            places_and_points[place] for place in data["from_station_name"] if place in places_and_points.keys()
-        ]
-
-    if start_or_stop == "stop":
-        points = [
-            places_and_points[place] for place in data["to_station_name"] if place in places_and_points.keys()
-        ]
-
-    data[f"{start_or_stop}_latitude"] = pd.Series([point[0] for point in points])
-    data[f"{start_or_stop}_longitude"] = pd.Series([point[1] for point in points])
-
-
-# FIND COLUMNS THAT CONTAIN STRINGS
-def find_rows_with_zeros(
-        data: pd.DataFrame,
-        column_index: int
-):
-
-    return [
-        row for row in tqdm(range(data.shape[0])) if data.iloc[row, column_index] == 0
-    ]
-
-
-def reveal_final_unknown_lats(
-        data: pd.DataFrame,
-        column_of_coordinate: str
-):
-
-    return [
-            row for row in tqdm(range(data.shape[0])) if data.iloc[
-                                                             row, data.columns.get_loc(column_of_coordinate)] == 0
-    ]
Index: .idea/.gitignore
===================================================================
diff --git a/.idea/.gitignore b/.idea/.gitignore
deleted file mode 100644
--- a/.idea/.gitignore	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ /dev/null	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
@@ -1,8 +0,0 @@
-# Default ignored files
-/shelf/
-/workspace.xml
-# Editor-based HTTP Client requests
-/httpRequests/
-# Datasource local storage ignored files
-/dataSources/
-/dataSources.local.xml
Index: .idea/cyclistic-bike-sharing-data.iml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<module type=\"PYTHON_MODULE\" version=\"4\">\n  <component name=\"NewModuleRootManager\">\n    <content url=\"file://$MODULE_DIR$\">\n      <excludeFolder url=\"file://$MODULE_DIR$/.venv\" />\n    </content>\n    <orderEntry type=\"jdk\" jdkName=\"Python 3.11 (cyclistic-bike-sharing-data)\" jdkType=\"Python SDK\" />\n    <orderEntry type=\"sourceFolder\" forTests=\"false\" />\n  </component>\n  <component name=\"PyDocumentationSettings\">\n    <option name=\"format\" value=\"PLAIN\" />\n    <option name=\"myDocStringFormat\" value=\"Plain\" />\n  </component>\n  <component name=\"TestRunnerService\">\n    <option name=\"PROJECT_TEST_RUNNER\" value=\"py.test\" />\n  </component>\n</module>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/cyclistic-bike-sharing-data.iml b/.idea/cyclistic-bike-sharing-data.iml
--- a/.idea/cyclistic-bike-sharing-data.iml	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ b/.idea/cyclistic-bike-sharing-data.iml	(date 1704056567467)
@@ -11,7 +11,4 @@
     <option name="format" value="PLAIN" />
     <option name="myDocStringFormat" value="Plain" />
   </component>
-  <component name="TestRunnerService">
-    <option name="PROJECT_TEST_RUNNER" value="py.test" />
-  </component>
 </module>
\ No newline at end of file
Index: .idea/workspace.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<project version=\"4\">\n  <component name=\"AutoImportSettings\">\n    <option name=\"autoReloadType\" value=\"SELECTIVE\" />\n  </component>\n  <component name=\"ChangeListManager\">\n    <list default=\"true\" id=\"2a4a8d73-eeff-4452-b5f1-f0c5212b4041\" name=\"Changes\" comment=\"\">\n      <change afterPath=\"$PROJECT_DIR$/.idea/.gitignore\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/cyclistic-bike-sharing-data.iml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/misc.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/modules.xml\" afterDir=\"false\" />\n      <change afterPath=\"$PROJECT_DIR$/.idea/vcs.xml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/notebooks/01_LOAD_AND_SAVE_RAW_DATA.ipynb\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/notebooks/01_LOAD_AND_SAVE_RAW_DATA.ipynb\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/notebooks/02_MEMORY_MANAGEMENT.ipynb\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/notebooks/02_MEMORY_MANAGEMENT.ipynb\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/notebooks/03_DATA_CLEANING.ipynb\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/notebooks/03_DATA_CLEANING.ipynb\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/poetry.lock\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/poetry.lock\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/pyproject.toml\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/pyproject.toml\" afterDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/src/core/data.py\" beforeDir=\"false\" />\n      <change beforePath=\"$PROJECT_DIR$/src/core/paths.py\" beforeDir=\"false\" afterPath=\"$PROJECT_DIR$/src/core/paths.py\" afterDir=\"false\" />\n    </list>\n    <option name=\"SHOW_DIALOG\" value=\"false\" />\n    <option name=\"HIGHLIGHT_CONFLICTS\" value=\"true\" />\n    <option name=\"HIGHLIGHT_NON_ACTIVE_CHANGELIST\" value=\"false\" />\n    <option name=\"LAST_RESOLUTION\" value=\"IGNORE\" />\n  </component>\n  <component name=\"FileTemplateManagerImpl\">\n    <option name=\"RECENT_TEMPLATES\">\n      <list>\n        <option value=\"Jupyter Notebook\" />\n      </list>\n    </option>\n  </component>\n  <component name=\"Git.Settings\">\n    <option name=\"RECENT_GIT_ROOT_PATH\" value=\"$PROJECT_DIR$\" />\n  </component>\n  <component name=\"MarkdownSettingsMigration\">\n    <option name=\"stateVersion\" value=\"1\" />\n  </component>\n  <component name=\"ProblemsViewState\">\n    <option name=\"selectedTabId\" value=\"CurrentFile\" />\n  </component>\n  <component name=\"ProjectColorInfo\">{\n  &quot;associatedIndex&quot;: 3\n}</component>\n  <component name=\"ProjectId\" id=\"2Zgns3lc4VMtoLwKIA55uUQapo3\" />\n  <component name=\"ProjectLevelVcsManager\" settingsEditedManually=\"true\" />\n  <component name=\"ProjectViewState\">\n    <option name=\"hideEmptyMiddlePackages\" value=\"true\" />\n    <option name=\"showLibraryContents\" value=\"true\" />\n  </component>\n  <component name=\"PropertiesComponent\"><![CDATA[{\n  \"keyToString\": {\n    \"RunOnceActivity.OpenProjectViewOnStart\": \"true\",\n    \"RunOnceActivity.ShowReadmeOnStart\": \"true\",\n    \"git-widget-placeholder\": \"main\",\n    \"last_opened_file_path\": \"/home/kobina/.cache/JetBrains/DataSpell2023.3/demo/ds/dataspell_demo\",\n    \"nodejs_package_manager_path\": \"npm\",\n    \"settings.editor.selected.configurable\": \"preferences.pluginManager\",\n    \"vue.rearranger.settings.migration\": \"true\"\n  },\n  \"keyToStringList\": {\n    \"DatabaseDriversLRU\": [\n      \"mysql_aurora_aws\"\n    ]\n  }\n}]]></component>\n  <component name=\"SharedIndexes\">\n    <attachedChunks>\n      <set>\n        <option value=\"bundled-python-sdk-f630212fe81e-c6172f9078bd-com.jetbrains.pycharm.ds.sharedIndexes.bundled-DS-233.11799.285\" />\n      </set>\n    </attachedChunks>\n  </component>\n  <component name=\"SpellCheckerSettings\" RuntimeDictionaries=\"0\" Folders=\"0\" CustomDictionaries=\"0\" DefaultDictionary=\"application-level\" UseSingleDictionary=\"true\" transferred=\"true\" />\n  <component name=\"TaskManager\">\n    <task active=\"true\" id=\"Default\" summary=\"Default task\">\n      <changelist id=\"2a4a8d73-eeff-4452-b5f1-f0c5212b4041\" name=\"Changes\" comment=\"\" />\n      <created>1702873982192</created>\n      <option name=\"number\" value=\"Default\" />\n      <option name=\"presentableId\" value=\"Default\" />\n      <updated>1702873982192</updated>\n      <workItem from=\"1702873983193\" duration=\"62000\" />\n    </task>\n    <servers />\n  </component>\n  <component name=\"TypeScriptGeneratedFilesManager\">\n    <option name=\"version\" value=\"3\" />\n  </component>\n  <component name=\"Vcs.Log.Tabs.Properties\">\n    <option name=\"TAB_STATES\">\n      <map>\n        <entry key=\"MAIN\">\n          <value>\n            <State />\n          </value>\n        </entry>\n      </map>\n    </option>\n  </component>\n  <component name=\"XDebuggerManager\">\n    <breakpoint-manager>\n      <default-breakpoints>\n        <breakpoint type=\"python-exception\">\n          <properties notifyOnTerminate=\"true\" exception=\"BaseException\">\n            <option name=\"notifyOnTerminate\" value=\"true\" />\n          </properties>\n        </breakpoint>\n      </default-breakpoints>\n    </breakpoint-manager>\n  </component>\n</project>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/workspace.xml b/.idea/workspace.xml
--- a/.idea/workspace.xml	(revision 50db3505330b7303becd56e26173e48c6ac0bfa8)
+++ b/.idea/workspace.xml	(date 1704302597011)
@@ -4,20 +4,24 @@
     <option name="autoReloadType" value="SELECTIVE" />
   </component>
   <component name="ChangeListManager">
-    <list default="true" id="2a4a8d73-eeff-4452-b5f1-f0c5212b4041" name="Changes" comment="">
-      <change afterPath="$PROJECT_DIR$/.idea/.gitignore" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/cyclistic-bike-sharing-data.iml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/misc.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/modules.xml" afterDir="false" />
-      <change afterPath="$PROJECT_DIR$/.idea/vcs.xml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/notebooks/01_LOAD_AND_SAVE_RAW_DATA.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/notebooks/01_LOAD_AND_SAVE_RAW_DATA.ipynb" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/notebooks/02_MEMORY_MANAGEMENT.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/notebooks/02_MEMORY_MANAGEMENT.ipynb" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/notebooks/03_DATA_CLEANING.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/notebooks/03_DATA_CLEANING.ipynb" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/poetry.lock" beforeDir="false" afterPath="$PROJECT_DIR$/poetry.lock" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/pyproject.toml" beforeDir="false" afterPath="$PROJECT_DIR$/pyproject.toml" afterDir="false" />
-      <change beforePath="$PROJECT_DIR$/src/core/data.py" beforeDir="false" />
-      <change beforePath="$PROJECT_DIR$/src/core/paths.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/core/paths.py" afterDir="false" />
+    <list default="true" id="473ac731-8acf-4439-88a9-b00ce8ae677e" name="Changes" comment="Generating the time series requires grouping by station IDs. It also became necessary to restrict the work to 2023 data.">
+      <change afterPath="$PROJECT_DIR$/notebooks/05_TRANSFORM_TS_DATA_INTO_TRAINING_DATA.ipynb" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/notebooks/06_TRANSFORM_RAW_DATA_INTO_TRAINING_DATA.ipynb" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/notebooks/08_BASELINE_MODEL.ipynb" afterDir="false" />
+      <change afterPath="$PROJECT_DIR$/src/data_splitting.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.gitignore" beforeDir="false" afterPath="$PROJECT_DIR$/.gitignore" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/.gitignore" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/cyclistic-bike-sharing-data.iml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/cyclistic-bike-sharing-data.iml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/inspectionProfiles/Project_Default.xml" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/.idea/workspace.xml" beforeDir="false" afterPath="$PROJECT_DIR$/.idea/workspace.xml" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/notebooks/04_TRANSFORM_DATA_INTO_TIME_SERIES.ipynb" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/notebooks/04_TRANSFORM_DATA_INTO_TS_DATA.ipynb" beforeDir="false" afterPath="$PROJECT_DIR$/notebooks/04_TRANSFORM_CLEANED_DATA_INTO_TS_DATA.ipynb" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/core/data_extraction.py" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/core/miscellaneous.py" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/core/paths.py" beforeDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/data_extraction.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/data_extraction.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/data_transformations.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/data_transformations.py" afterDir="false" />
+      <change beforePath="$PROJECT_DIR$/src/miscellaneous.py" beforeDir="false" afterPath="$PROJECT_DIR$/src/miscellaneous.py" afterDir="false" />
     </list>
     <option name="SHOW_DIALOG" value="false" />
     <option name="HIGHLIGHT_CONFLICTS" value="true" />
@@ -28,10 +32,16 @@
     <option name="RECENT_TEMPLATES">
       <list>
         <option value="Jupyter Notebook" />
+        <option value="Python Script" />
       </list>
     </option>
   </component>
   <component name="Git.Settings">
+    <option name="PREVIOUS_COMMIT_AUTHORS">
+      <list>
+        <option value="Kobina Brandon &lt;maadabrandon@protonmail.com&gt;" />
+      </list>
+    </option>
     <option name="RECENT_GIT_ROOT_PATH" value="$PROJECT_DIR$" />
   </component>
   <component name="MarkdownSettingsMigration">
@@ -41,10 +51,10 @@
     <option name="selectedTabId" value="CurrentFile" />
   </component>
   <component name="ProjectColorInfo">{
+  &quot;customColor&quot;: &quot;&quot;,
   &quot;associatedIndex&quot;: 3
 }</component>
-  <component name="ProjectId" id="2Zgns3lc4VMtoLwKIA55uUQapo3" />
-  <component name="ProjectLevelVcsManager" settingsEditedManually="true" />
+  <component name="ProjectId" id="2aDbvOunH0KkrWY3hVR79oosSJT" />
   <component name="ProjectViewState">
     <option name="hideEmptyMiddlePackages" value="true" />
     <option name="showLibraryContents" value="true" />
@@ -54,15 +64,13 @@
     "RunOnceActivity.OpenProjectViewOnStart": "true",
     "RunOnceActivity.ShowReadmeOnStart": "true",
     "git-widget-placeholder": "main",
-    "last_opened_file_path": "/home/kobina/.cache/JetBrains/DataSpell2023.3/demo/ds/dataspell_demo",
+    "node.js.detected.package.eslint": "true",
+    "node.js.detected.package.tslint": "true",
+    "node.js.selected.package.eslint": "(autodetect)",
+    "node.js.selected.package.tslint": "(autodetect)",
     "nodejs_package_manager_path": "npm",
-    "settings.editor.selected.configurable": "preferences.pluginManager",
+    "settings.editor.selected.configurable": "configurable.group.tools",
     "vue.rearranger.settings.migration": "true"
-  },
-  "keyToStringList": {
-    "DatabaseDriversLRU": [
-      "mysql_aurora_aws"
-    ]
   }
 }]]></component>
   <component name="SharedIndexes">
@@ -75,13 +83,28 @@
   <component name="SpellCheckerSettings" RuntimeDictionaries="0" Folders="0" CustomDictionaries="0" DefaultDictionary="application-level" UseSingleDictionary="true" transferred="true" />
   <component name="TaskManager">
     <task active="true" id="Default" summary="Default task">
-      <changelist id="2a4a8d73-eeff-4452-b5f1-f0c5212b4041" name="Changes" comment="" />
-      <created>1702873982192</created>
+      <changelist id="473ac731-8acf-4439-88a9-b00ce8ae677e" name="Changes" comment="" />
+      <created>1703940300721</created>
       <option name="number" value="Default" />
       <option name="presentableId" value="Default" />
-      <updated>1702873982192</updated>
-      <workItem from="1702873983193" duration="62000" />
+      <updated>1703940300721</updated>
+      <workItem from="1703940303189" duration="5000" />
+      <workItem from="1703979730556" duration="500000" />
+      <workItem from="1704054740460" duration="1703000" />
+      <workItem from="1704056514055" duration="4026000" />
+      <workItem from="1704123694982" duration="8053000" />
+      <workItem from="1704150105595" duration="6814000" />
+      <workItem from="1704183508968" duration="20362000" />
     </task>
+    <task id="LOCAL-00001" summary="Generating the time series requires grouping by station IDs. It also became necessary to restrict the work to 2023 data.">
+      <option name="closed" value="true" />
+      <created>1704151692198</created>
+      <option name="number" value="00001" />
+      <option name="presentableId" value="LOCAL-00001" />
+      <option name="project" value="LOCAL" />
+      <updated>1704151692198</updated>
+    </task>
+    <option name="localTasksCounter" value="2" />
     <servers />
   </component>
   <component name="TypeScriptGeneratedFilesManager">
@@ -92,21 +115,21 @@
       <map>
         <entry key="MAIN">
           <value>
-            <State />
+            <State>
+              <option name="CUSTOM_BOOLEAN_PROPERTIES">
+                <map>
+                  <entry key="Show.Git.Branches" value="true" />
+                </map>
+              </option>
+            </State>
           </value>
         </entry>
       </map>
     </option>
   </component>
-  <component name="XDebuggerManager">
-    <breakpoint-manager>
-      <default-breakpoints>
-        <breakpoint type="python-exception">
-          <properties notifyOnTerminate="true" exception="BaseException">
-            <option name="notifyOnTerminate" value="true" />
-          </properties>
-        </breakpoint>
-      </default-breakpoints>
-    </breakpoint-manager>
+  <component name="VcsManagerConfiguration">
+    <MESSAGE value="Generating the time series may require grouping by station IDs" />
+    <MESSAGE value="Generating the time series requires grouping by station IDs. It also became necessary to restrict the work to 2023 data." />
+    <option name="LAST_COMMIT_MESSAGE" value="Generating the time series requires grouping by station IDs. It also became necessary to restrict the work to 2023 data." />
   </component>
 </project>
\ No newline at end of file
