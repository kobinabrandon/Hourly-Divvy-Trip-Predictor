{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Transform the data into a complete time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T15:44:04.683347093Z",
     "start_time": "2024-01-02T15:44:04.293743556Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.paths import CLEANED_DATA, TRANSFORMED_DATA, GEOGRAPHICAL_DATA\n",
    "from src.data_transformations import add_missing_slots\n",
    "from src.miscellaneous import add_rounded_coordinates_to_dataframe, add_column_of_rounded_points, make_new_station_ids,save_dict, add_column_of_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the cleaned 2023 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T14:13:28.755460302Z",
     "start_time": "2024-01-02T14:13:28.289973287Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>start_latitude</th>\n",
       "      <th>start_longitude</th>\n",
       "      <th>stop_latitude</th>\n",
       "      <th>stop_longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-21 20:05:42</td>\n",
       "      <td>2023-01-21 20:16:33</td>\n",
       "      <td>41.924074</td>\n",
       "      <td>-87.646278</td>\n",
       "      <td>41.930000</td>\n",
       "      <td>-87.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-10 15:37:36</td>\n",
       "      <td>2023-01-10 15:46:05</td>\n",
       "      <td>41.799568</td>\n",
       "      <td>-87.594747</td>\n",
       "      <td>41.809835</td>\n",
       "      <td>-87.599383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02 07:51:57</td>\n",
       "      <td>2023-01-02 08:05:11</td>\n",
       "      <td>42.008571</td>\n",
       "      <td>-87.690483</td>\n",
       "      <td>42.039742</td>\n",
       "      <td>-87.699413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-22 10:52:58</td>\n",
       "      <td>2023-01-22 11:01:44</td>\n",
       "      <td>41.799568</td>\n",
       "      <td>-87.594747</td>\n",
       "      <td>41.809835</td>\n",
       "      <td>-87.599383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-12 13:58:01</td>\n",
       "      <td>2023-01-12 14:13:20</td>\n",
       "      <td>41.799568</td>\n",
       "      <td>-87.594747</td>\n",
       "      <td>41.809835</td>\n",
       "      <td>-87.599383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_time           stop_time  start_latitude  start_longitude  \\\n",
       "0 2023-01-21 20:05:42 2023-01-21 20:16:33       41.924074       -87.646278   \n",
       "1 2023-01-10 15:37:36 2023-01-10 15:46:05       41.799568       -87.594747   \n",
       "2 2023-01-02 07:51:57 2023-01-02 08:05:11       42.008571       -87.690483   \n",
       "3 2023-01-22 10:52:58 2023-01-22 11:01:44       41.799568       -87.594747   \n",
       "4 2023-01-12 13:58:01 2023-01-12 14:13:20       41.799568       -87.594747   \n",
       "\n",
       "   stop_latitude  stop_longitude  \n",
       "0      41.930000      -87.640000  \n",
       "1      41.809835      -87.599383  \n",
       "2      42.039742      -87.699413  \n",
       "3      41.809835      -87.599383  \n",
       "4      41.809835      -87.599383  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = pd.read_parquet(path = CLEANED_DATA/\"final.parquet\")\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the time stamps to hour-based values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T14:13:29.034557841Z",
     "start_time": "2024-01-02T14:13:28.802676497Z"
    }
   },
   "outputs": [],
   "source": [
    "trips[\"start_hour\"] = trips[\"start_time\"].dt.floor(\"H\")\n",
    "trips[\"stop_hour\"] = trips[\"stop_time\"].dt.floor(\"H\")\n",
    "\n",
    "trips = trips.drop(columns = [\"start_time\", \"stop_time\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Starts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T14:13:29.118011018Z",
     "start_time": "2024-01-02T14:13:29.029898009Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = trips[\n",
    "    [\n",
    "        \"start_hour\", \"start_latitude\", \"start_longitude\"\n",
    "    ]\n",
    "] \n",
    "\n",
    "\n",
    "stops = trips[\n",
    "    [\n",
    "        \"stop_hour\", \"stop_latitude\", \"stop_longitude\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save original coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T14:13:31.177227859Z",
     "start_time": "2024-01-02T14:13:29.121545413Z"
    }
   },
   "outputs": [],
   "source": [
    "starts[[\"start_latitude\", \"start_longitude\"]].to_parquet(path = GEOGRAPHICAL_DATA/ \"original_start_coordinates.parquet\") \n",
    "\n",
    "stops[[\"stop_latitude\", \"stop_longitude\"]].to_parquet(path = GEOGRAPHICAL_DATA/ \"original_stop_coordinates.parquet\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Round the coordinates to two decimal places to make grouping easier, and remove the old latitude and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T14:13:35.006191716Z",
     "start_time": "2024-01-02T14:13:31.173490070Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 710872/5495778 [00:04<00:31, 154236.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3550, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_15038/963484252.py\", line 1, in <module>\n",
      "    add_rounded_coordinates_to_dataframe(data = starts, decimal_places = 3, start_or_stop = \"start\")\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/src/miscellaneous.py\", line 50, in add_rounded_coordinates_to_dataframe\n",
      "    for latitude in tqdm(data[f\"{start_or_stop}_latitude\"].values):\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/tqdm/std.py\", line -1, in __iter__\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/home/kobina/Desktop/ML/End-to-End Projects/Actualised/cyclistic-bike-sharing-data/.venv/lib/python3.11/site-packages/executing/executing.py\", line 116, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "add_rounded_coordinates_to_dataframe(data = starts, decimal_places = 3, start_or_stop = \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:34.997997211Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5495778/5495778 [00:27<00:00, 198037.49it/s]\n",
      "100%|██████████| 5495778/5495778 [00:29<00:00, 183652.14it/s]\n"
     ]
    }
   ],
   "source": [
    "add_rounded_coordinates_to_dataframe(data = stops, decimal_places = 3, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Remove original coordinates, and put those tuples in a dedicated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:34.998431234Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "starts = starts.drop(columns = [\"start_latitude\", \"start_longitude\"])\n",
    "stops = stops.drop(columns = [\"stop_latitude\", \"stop_longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Add columns of consisting of tuples of rounded coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:34.998805263Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_column_of_rounded_points(data = starts, start_or_stop = \"start\")\n",
    "add_column_of_rounded_points(data = stops, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:34.999872822Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = starts.drop(columns = [\"rounded_start_latitude\", \"rounded_start_longitude\"])\n",
    "stops = stops.drop(columns = [\"rounded_stop_latitude\", \"rounded_stop_longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make new location IDs, and associate each of them to a point using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.000305670Z"
    }
   },
   "outputs": [],
   "source": [
    "places_and_ids = make_new_station_ids(start_df = starts, stop_df = stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensuring that any points common to the origins and destinations have the same IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We have made dictionaries associating the origins and destinations with IDs, but some of the destinations and origins may be the same. And they will have been assigned to different IDs. These common locations (or rather, their coordinates) must be assigned to the same ID in each dictionary.\n",
    "\n",
    "\n",
    "###### First, let us find out how many of these points are common to these dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.000749862Z"
    }
   },
   "outputs": [],
   "source": [
    "common_points = [point for point in destinations_and_ids.keys() if point in origins_and_ids.keys()]\n",
    "len(common_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are 2,357 common locations. And they will most likely have been assigned to different IDs in each dictionary.\n",
    "###### Let us ensure that these common points have the same IDs in each dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.001127Z"
    }
   },
   "outputs": [],
   "source": [
    "for point in common_points:\n",
    "\n",
    "        destinations_and_ids[point] = origins_and_ids[point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking for repetition of origin IDs. The presence of repeated values necessitates a deeper investigation into whether they are shared by two different points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.001499389Z"
    }
   },
   "outputs": [],
   "source": [
    "len(origins_and_ids.values()) == len(set(origins_and_ids.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are no repeated origin IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.001899942Z"
    }
   },
   "outputs": [],
   "source": [
    "len(destinations_and_ids.values()) == len(set(destinations_and_ids.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are some repeated destination IDs. Let us check whether they belong to the same points or not. If they belong to two different points, then that will have to be rectified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.002384422Z"
    }
   },
   "outputs": [],
   "source": [
    "for a,b in zip(destinations_and_ids.keys(), destinations_and_ids.keys()):\n",
    "\n",
    "    if destinations_and_ids[a] == destinations_and_ids[b] and a != b:\n",
    "\n",
    "        print((a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All clear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.003006614Z"
    }
   },
   "outputs": [],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save these dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This is crucial because it will allow me to recall this particular association of coordinates with IDs later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.003390285Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dict(\n",
    "    folder = GEOGRAPHICAL_DATA, \n",
    "    dictionary = origins_and_ids, \n",
    "    file_name = \"rounded_origin_points_and_their_IDs.pkl\"\n",
    "    )\n",
    "\n",
    "save_dict(\n",
    "    folder = GEOGRAPHICAL_DATA, \n",
    "    dictionary = destinations_and_ids, \n",
    "    file_name = \"rounded_destination_points_and_their_IDs.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Form a column of said IDs (in the appropriate order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.049112317Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "add_column_of_ids(data = starts, start_or_stop = \"start\", points_and_ids = origins_and_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.049414444Z"
    }
   },
   "outputs": [],
   "source": [
    "add_column_of_ids(data = stops, start_or_stop = \"stop\", points_and_ids = destinations_and_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Form Aggregate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.049712756Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = starts.drop(\"rounded_start_points\", axis = 1)\n",
    "stops = stops.drop(\"rounded_stop_points\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Aggregate Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.049930690Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agg_starts = starts.groupby([\"start_hour\", \"start_station_id\"]).size().reset_index()\n",
    "agg_starts = agg_starts.rename(columns = {0: \"trips\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Aggregate Starts with Missing Slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.050123927Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_starts = add_missing_slots(agg_data = agg_starts, start_or_stop = \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.050348109Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_starts.to_parquet(path = TRANSFORMED_DATA/\"ts_starts.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.050558985Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_stops = stops.groupby([\"stop_hour\", \"stop_station_id\"]).size().reset_index()\n",
    "agg_stops = agg_stops.rename(columns = {0: \"trips\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Aggregate Stops with Missing Slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.050804715Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_stops = add_missing_slots(agg_data = agg_stops, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-01-02T14:13:35.051037452Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_stops.to_parquet(path = TRANSFORMED_DATA/\"ts_stops.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-02T15:15:04.593111349Z",
     "start_time": "2024-01-02T15:15:04.590929176Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3\n",
      "2 4\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip([1,2], [3,4]):\n",
    "    \n",
    "    print(i,j)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
