{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Transform the data into a complete time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:56:05.278033696Z",
     "start_time": "2024-01-01T15:56:05.120096853Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.paths import CLEANED_DATA, TRANSFORMED_DATA, GEOGRAPHICAL_DATA\n",
    "from src.data_transformations import add_missing_slots\n",
    "from src.miscellaneous import add_rounded_coordinates_to_dataframe, add_column_of_rounded_points, make_new_station_ids,save_dict, add_column_of_ids "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the cleaned 2023 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:56:05.534175094Z",
     "start_time": "2024-01-01T15:56:05.282809841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           start_time           stop_time  start_latitude  start_longitude  \\\n0 2023-01-21 20:05:42 2023-01-21 20:16:33       41.924074       -87.646278   \n1 2023-01-10 15:37:36 2023-01-10 15:46:05       41.799568       -87.594747   \n2 2023-01-02 07:51:57 2023-01-02 08:05:11       42.008571       -87.690483   \n3 2023-01-22 10:52:58 2023-01-22 11:01:44       41.799568       -87.594747   \n4 2023-01-12 13:58:01 2023-01-12 14:13:20       41.799568       -87.594747   \n\n   stop_latitude  stop_longitude  \n0      41.930000      -87.640000  \n1      41.809835      -87.599383  \n2      42.039742      -87.699413  \n3      41.809835      -87.599383  \n4      41.809835      -87.599383  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>start_time</th>\n      <th>stop_time</th>\n      <th>start_latitude</th>\n      <th>start_longitude</th>\n      <th>stop_latitude</th>\n      <th>stop_longitude</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-01-21 20:05:42</td>\n      <td>2023-01-21 20:16:33</td>\n      <td>41.924074</td>\n      <td>-87.646278</td>\n      <td>41.930000</td>\n      <td>-87.640000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-01-10 15:37:36</td>\n      <td>2023-01-10 15:46:05</td>\n      <td>41.799568</td>\n      <td>-87.594747</td>\n      <td>41.809835</td>\n      <td>-87.599383</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-01-02 07:51:57</td>\n      <td>2023-01-02 08:05:11</td>\n      <td>42.008571</td>\n      <td>-87.690483</td>\n      <td>42.039742</td>\n      <td>-87.699413</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-01-22 10:52:58</td>\n      <td>2023-01-22 11:01:44</td>\n      <td>41.799568</td>\n      <td>-87.594747</td>\n      <td>41.809835</td>\n      <td>-87.599383</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-01-12 13:58:01</td>\n      <td>2023-01-12 14:13:20</td>\n      <td>41.799568</td>\n      <td>-87.594747</td>\n      <td>41.809835</td>\n      <td>-87.599383</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trips = pd.read_parquet(path = CLEANED_DATA/\"final.parquet\")\n",
    "trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce the time stamps to hour-based values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:56:05.803504908Z",
     "start_time": "2024-01-01T15:56:05.610096958Z"
    }
   },
   "outputs": [],
   "source": [
    "trips[\"start_hour\"] = trips[\"start_time\"].dt.floor(\"H\")\n",
    "trips[\"stop_hour\"] = trips[\"stop_time\"].dt.floor(\"H\")\n",
    "\n",
    "trips.drop(columns = [\"start_time\", \"stop_time\"], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Starts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:56:05.874250312Z",
     "start_time": "2024-01-01T15:56:05.799670208Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = trips[\n",
    "    [\n",
    "        \"start_hour\", \"start_latitude\", \"start_longitude\"\n",
    "    ]\n",
    "] \n",
    "\n",
    "\n",
    "stops = trips[\n",
    "    [\n",
    "        \"stop_hour\", \"stop_latitude\", \"stop_longitude\"\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save original coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:56:07.791201720Z",
     "start_time": "2024-01-01T15:56:05.901419025Z"
    }
   },
   "outputs": [],
   "source": [
    "starts[[\"start_latitude\", \"start_longitude\"]].to_parquet(path = GEOGRAPHICAL_DATA/ \"original_start_coordinates.parquet\") \n",
    "stops[[\"stop_latitude\", \"stop_longitude\"]].to_parquet(path = GEOGRAPHICAL_DATA/ \"original_stop_coordinates.parquet\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Round the coordinates to two decimal places to make grouping easier, and remove the old latitude and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:57:19.601684567Z",
     "start_time": "2024-01-01T15:56:07.837476742Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5495778/5495778 [00:34<00:00, 158455.35it/s]\n",
      "100%|██████████| 5495778/5495778 [00:34<00:00, 159723.89it/s]\n"
     ]
    }
   ],
   "source": [
    "add_rounded_coordinates_to_dataframe(data = starts, decimal_places = 3, start_or_stop = \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:30.020499766Z",
     "start_time": "2024-01-01T15:57:19.604857046Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5495778/5495778 [00:34<00:00, 161258.13it/s]\n",
      "100%|██████████| 5495778/5495778 [00:33<00:00, 163418.29it/s]\n"
     ]
    }
   ],
   "source": [
    "add_rounded_coordinates_to_dataframe(data = stops, decimal_places = 3, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Remove original coordinates, and put those tuples in a dedicated column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:30.129335226Z",
     "start_time": "2024-01-01T15:58:30.025051444Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = starts.drop(columns = [\"start_latitude\", \"start_longitude\"])\n",
    "stops = stops.drop(columns = [\"stop_latitude\", \"stop_longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Add columns of consisting of tuples of rounded coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:34.187935553Z",
     "start_time": "2024-01-01T15:58:30.151290799Z"
    }
   },
   "outputs": [],
   "source": [
    "add_column_of_rounded_points(data = starts, start_or_stop = \"start\")\n",
    "add_column_of_rounded_points(data = stops, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:34.377293696Z",
     "start_time": "2024-01-01T15:58:34.191553018Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = starts.drop(columns = [\"rounded_start_latitude\", \"rounded_start_longitude\"])\n",
    "stops = stops.drop(columns = [\"rounded_stop_latitude\", \"rounded_stop_longitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Make new location IDs, and associate each of them to a point using a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.004729480Z",
     "start_time": "2024-01-01T15:58:35.630143288Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1833it [00:00, 1318949.95it/s]\n",
      "1241it [00:00, 1537704.95it/s]\n"
     ]
    }
   ],
   "source": [
    "origins_and_ids = make_new_station_ids(data = starts, start_or_stop = \"start\")\n",
    "destinations_and_ids = make_new_station_ids(data = stops, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ensuring that any points common to the origins and destinations have the same IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### We have made dictionaries associating the origins and destinations with IDs, but some of the destinations and origins may be the same. And they will have been assigned to different IDs. These common locations (or rather, their coordinates) must be assigned to the same ID in each dictionary.\n",
    "\n",
    "\n",
    "###### First, let us find out how many of these points are common to these dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.007971999Z",
     "start_time": "2024-01-01T15:58:36.997545959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "1168"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_points = [point for point in destinations_and_ids.keys() if point in origins_and_ids.keys()]\n",
    "len(common_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are 2,357 common locations. And they will most likely have been assigned to different IDs in each dictionary.\n",
    "###### Let us assign ensure that these common points have the same IDs in each dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.009679763Z",
     "start_time": "2024-01-01T15:58:36.997800907Z"
    }
   },
   "outputs": [],
   "source": [
    "for point in common_points:\n",
    "\n",
    "        destinations_and_ids[point] = origins_and_ids[point]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Checking for repetition of origin IDs. The presence of repeated values necessitates a deeper investigation into whether they are shared by two different points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.014907347Z",
     "start_time": "2024-01-01T15:58:36.997991738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(origins_and_ids.values()) == len(set(origins_and_ids.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are no repeated origin IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.016619665Z",
     "start_time": "2024-01-01T15:58:36.998123900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(destinations_and_ids.values()) == len(set(destinations_and_ids.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### There are some repeated destination IDs. Let us check whether they belong to the same points or not. If they belong to two different points, then that will have to be rectified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.017772453Z",
     "start_time": "2024-01-01T15:58:36.998301500Z"
    }
   },
   "outputs": [],
   "source": [
    "for a,b in zip(destinations_and_ids.keys(), destinations_and_ids.keys()):\n",
    "\n",
    "    if destinations_and_ids[a] == destinations_and_ids[b] and a != b:\n",
    "\n",
    "        print((a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### All clear!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.030967145Z",
     "start_time": "2024-01-01T15:58:37.004669457Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                 stop_hour rounded_stop_points\n0      2023-01-21 20:00:00     (41.93, -87.64)\n1      2023-01-10 15:00:00    (41.81, -87.599)\n2      2023-01-02 08:00:00    (42.04, -87.699)\n3      2023-01-22 11:00:00    (41.81, -87.599)\n4      2023-01-12 14:00:00    (41.81, -87.599)\n...                    ...                 ...\n362513 2023-11-24 08:00:00   (41.933, -87.636)\n362514 2023-11-06 09:00:00   (41.831, -87.627)\n362515 2023-11-10 19:00:00   (41.925, -87.689)\n362516 2023-11-27 09:00:00   (41.831, -87.627)\n362517 2023-11-20 16:00:00    (41.956, -87.68)\n\n[5495778 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stop_hour</th>\n      <th>rounded_stop_points</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2023-01-21 20:00:00</td>\n      <td>(41.93, -87.64)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2023-01-10 15:00:00</td>\n      <td>(41.81, -87.599)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2023-01-02 08:00:00</td>\n      <td>(42.04, -87.699)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2023-01-22 11:00:00</td>\n      <td>(41.81, -87.599)</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2023-01-12 14:00:00</td>\n      <td>(41.81, -87.599)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>362513</th>\n      <td>2023-11-24 08:00:00</td>\n      <td>(41.933, -87.636)</td>\n    </tr>\n    <tr>\n      <th>362514</th>\n      <td>2023-11-06 09:00:00</td>\n      <td>(41.831, -87.627)</td>\n    </tr>\n    <tr>\n      <th>362515</th>\n      <td>2023-11-10 19:00:00</td>\n      <td>(41.925, -87.689)</td>\n    </tr>\n    <tr>\n      <th>362516</th>\n      <td>2023-11-27 09:00:00</td>\n      <td>(41.831, -87.627)</td>\n    </tr>\n    <tr>\n      <th>362517</th>\n      <td>2023-11-20 16:00:00</td>\n      <td>(41.956, -87.68)</td>\n    </tr>\n  </tbody>\n</table>\n<p>5495778 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save these dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This is crucial because it will allow me to recall this particular association of coordinates with IDs later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:37.035641663Z",
     "start_time": "2024-01-01T15:58:37.012977966Z"
    }
   },
   "outputs": [],
   "source": [
    "save_dict(\n",
    "    folder = GEOGRAPHICAL_DATA, \n",
    "    dictionary = origins_and_ids, \n",
    "    file_name = \"rounded_origin_points_and_their_IDs.pkl\"\n",
    "    )\n",
    "\n",
    "save_dict(\n",
    "    folder = GEOGRAPHICAL_DATA, \n",
    "    dictionary = destinations_and_ids, \n",
    "    file_name = \"rounded_destination_points_and_their_IDs.pkl\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "##### Form a column of said IDs (in the appropriate order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:40.478131614Z",
     "start_time": "2024-01-01T15:58:37.408952204Z"
    }
   },
   "outputs": [],
   "source": [
    "add_column_of_ids(data = starts, start_or_stop = \"start\", points_and_ids = origins_and_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:44.374105274Z",
     "start_time": "2024-01-01T15:58:40.479199422Z"
    }
   },
   "outputs": [],
   "source": [
    "add_column_of_ids(data = stops, start_or_stop = \"stop\", points_and_ids = destinations_and_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Form Aggregate Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:44.593259816Z",
     "start_time": "2024-01-01T15:58:44.377533175Z"
    }
   },
   "outputs": [],
   "source": [
    "starts = starts.drop(\"rounded_start_points\", axis = 1)\n",
    "stops = stops.drop(\"rounded_stop_points\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Aggregate Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-01T15:58:45.693322123Z",
     "start_time": "2024-01-01T15:58:44.582859163Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_starts = starts.groupby([\"start_hour\", \"start_station_id\"]).size().reset_index()\n",
    "agg_starts = agg_starts.rename(columns = {0: \"trips\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Aggregate Starts with Missing Slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:59:55.604029788Z",
     "start_time": "2024-01-01T15:58:45.696155129Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1733/1733 [00:55<00:00, 31.10it/s]\n"
     ]
    }
   ],
   "source": [
    "ts_starts = add_missing_slots(agg_data = agg_starts, start_or_stop = \"start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:59:55.652767123Z",
     "start_time": "2024-01-01T15:59:41.725497158Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_starts.to_parquet(path = TRANSFORMED_DATA/\"ts_starts.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T15:59:55.655349366Z",
     "start_time": "2024-01-01T15:59:42.524010206Z"
    }
   },
   "outputs": [],
   "source": [
    "agg_stops = stops.groupby([\"stop_hour\", \"stop_station_id\"]).size().reset_index()\n",
    "agg_stops = agg_stops.rename(columns = {0: \"trips\"}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Aggregate Stops with Missing Slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T16:00:09.068637320Z",
     "start_time": "2024-01-01T15:59:43.478713412Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1164/1164 [00:25<00:00, 45.78it/s]\n"
     ]
    }
   ],
   "source": [
    "ts_stops = add_missing_slots(agg_data = agg_stops, start_or_stop = \"stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-01T16:00:09.966443553Z",
     "start_time": "2024-01-01T16:00:09.109400653Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_stops.to_parquet(path = TRANSFORMED_DATA/\"ts_stops.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
